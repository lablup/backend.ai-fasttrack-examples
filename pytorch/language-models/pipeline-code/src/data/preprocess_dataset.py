#!/usr/bin/env python3
"""
Task 1b: Dataset Preprocessing
ì›ë³¸ ë°ì´í„°ì…‹ì„ ë¶ˆëŸ¬ì™€ì„œ messages êµ¬ì¡°ë¡œ ë³€í™˜í•˜ëŠ” ì „ì²˜ë¦¬ íƒœìŠ¤í¬
- train/validation: í•™ìŠµìš© messages êµ¬ì¡° ìƒì„±
- test: í‰ê°€ìš© messages êµ¬ì¡° ìƒì„±

ì¼ë°˜í™”ëœ ë°ì´í„°ì…‹ ì „ì²˜ë¦¬ë¡œ ì‚¬ìš©ìê°€ configs/messages_format.yamlì„ í†µí•´
ë‹¤ì–‘í•œ ë°ì´í„°ì…‹ì— ì ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
"""

import os
import argparse
import yaml
from datasets import load_from_disk, DatasetDict
from pathlib import Path
from configs.settings import settings

def parse_args():
    parser = argparse.ArgumentParser(description="Dataset Preprocessor")
    parser.add_argument('--max_samples_per_split', type=int, default=None,
                        help='Maximum number of samples per split for testing (optional)')
    parser.add_argument('--config', type=str, default='messages_format.yaml',
                        help='Path to dataset configuration YAML file')
    return parser.parse_args()

def load_dataset_config(config_path: str) -> dict:
    """
    ë°ì´í„°ì…‹ ì„¤ì • YAML íŒŒì¼ì„ ë¡œë“œí•©ë‹ˆë‹¤.
    """
    config_file = settings.config_path / config_path
    print(f"Loading dataset config from: {config_file}")
    if not config_file.exists():
        raise FileNotFoundError(f"Dataset config file not found: {config_path}")
    
    with open(config_file, 'r', encoding='utf-8') as f:
        config = yaml.safe_load(f)
    
    # í•„ìˆ˜ ì„¤ì • í™•ì¸
    required_keys = ['training_columns', 'messages_format', 'evaluate_columns']
    for key in required_keys:
        if key not in config:
            raise ValueError(f"Missing required config key: {key}")
    
    return config

def create_training_messages(examples, training_columns: dict, messages_format: dict):
    """
    í•™ìŠµìš© messages êµ¬ì¡°ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
    
    Args:
        examples: HuggingFace dataset examples (batched format)
        training_columns: ì»¬ëŸ¼ ë§¤í•‘ ì •ë³´ (key: í…œí”Œë¦¿_ë³€ìˆ˜ëª…, value: ì‹¤ì œ_ë°ì´í„°ì…‹_ì»¬ëŸ¼ëª…)
        messages_format: messages í¬ë§· í…œí”Œë¦¿
    
    Returns:
        dict: {"messages": List[List[dict]], "reference": List[str]}
    """
    messages_list = []
    references_list = []
    
    # ì²« ë²ˆì§¸ ì»¬ëŸ¼ìœ¼ë¡œ ë°ì´í„° ê°œìˆ˜ í™•ì¸ (ëª¨ë“  ì»¬ëŸ¼ì€ ê°™ì€ ê¸¸ì´ë¥¼ ê°€ì§)
    first_column_name = list(training_columns.values())[0]
    batch_size = len(examples[first_column_name])
    
    # ë°°ì¹˜ì˜ ê° ìƒ˜í”Œì— ëŒ€í•´ ì²˜ë¦¬
    for idx in range(batch_size):
        # í…œí”Œë¦¿ ë³€ìˆ˜ì— ì‹¤ì œ ë°ì´í„° ê°’ ë§¤í•‘
        template_variables = {}
        for template_var, dataset_column in training_columns.items():
            template_variables[template_var] = examples[dataset_column][idx]
        
        # system_prompt ì¶”ê°€
        template_variables['system_prompt'] = messages_format['system_prompt']
        
        # messages êµ¬ì¡° ìƒì„± (roleê³¼ contentë¡œ êµ¬ì„±)
        messages = []
        for message_template in messages_format['messages']:
            content = message_template['content'].format(**template_variables)
            messages.append({
                "role": message_template['role'],
                "content": content
            })
        
        messages_list.append(messages)
        # responseë¥¼ referenceë¡œ ì €ì¥ (í‰ê°€ìš©)
        references_list.append(template_variables.get('response', ''))
    
    return {
        "messages": messages_list,
        "reference": references_list
    }

def create_evaluation_messages(examples, evaluate_columns: dict):
    """
    í‰ê°€ìš© messages êµ¬ì¡°ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
    
    Args:
        examples: HuggingFace dataset examples (batched format)
        evaluate_columns: í‰ê°€ìš© ì»¬ëŸ¼ ë§¤í•‘ ì •ë³´ (query, response í‚¤ í•„ìˆ˜)
    
    Returns:
        dict: {"messages": List[List[dict]], "reference": List[str], "question": List[str]}
    """
    messages_list = []
    references_list = []
    questions_list = []
    
    query_column_name = evaluate_columns['query']
    response_column_name = evaluate_columns['response']
    
    # ë°°ì¹˜ì˜ ê° ìƒ˜í”Œì— ëŒ€í•´ ì²˜ë¦¬
    for query, response in zip(examples[query_column_name], examples[response_column_name]):
        messages = [{"role": "user", "content": query}]
        messages_list.append(messages)
        references_list.append(response)
        questions_list.append(query)
    
    return {
        "messages": messages_list,
        "reference": references_list,
        "question": questions_list
    }

def preprocess_dataset(dataset: DatasetDict, config: dict, max_samples_per_split=None) -> DatasetDict:
    """
    ë°ì´í„°ì…‹ì„ messages êµ¬ì¡°ë¡œ ë³€í™˜í•˜ëŠ” ì „ì²˜ë¦¬ í•¨ìˆ˜
    - train/validation: í•™ìŠµìš© messages (system, user, assistant)
    - test: í‰ê°€ìš© messages (userë§Œ í¬í•¨, reference ë³„ë„ ì €ì¥)
    
    Args:
        dataset: ì›ë³¸ ë°ì´í„°ì…‹
        config: ë°ì´í„°ì…‹ ì„¤ì • ì •ë³´
        max_samples_per_split: ìµœëŒ€ ìƒ˜í”Œ ìˆ˜ ì œí•œ
    """
    print("Starting dataset preprocessing...")
    
    training_columns = config['training_columns']
    messages_format = config['messages_format']
    evaluate_columns = config['evaluate_columns']
    data_filtering = config.get('data_filtering', {})
    
    # í•„ìˆ˜ ì»¬ëŸ¼ í™•ì¸
    required_columns = data_filtering.get('required_columns', [])
    if required_columns:
        for split_name, split_data in dataset.items():
            missing_columns = [col for col in required_columns if col not in split_data.column_names]
            if missing_columns:
                raise ValueError(f"Missing required columns in {split_name} split: {missing_columns}")
    
    preprocessed_dataset = {}
    min_text_length = data_filtering.get('min_text_length', 1)
    
    for split_name, split_data in dataset.items():
        print(f"Preprocessing {split_name} split...")
        
        # ë°ì´í„° í’ˆì§ˆ í•„í„°ë§
        if required_columns:
            def filter_data(example):
                for col in required_columns:
                    if (example[col] is None or 
                        len(str(example[col]).strip()) < min_text_length):
                        return False
                return True
            
            filtered_data = split_data.filter(
                filter_data,
                desc=f"Filtering {split_name} data"
            )
        else:
            filtered_data = split_data
        
        # ìƒ˜í”Œ ìˆ˜ ì œí•œ (í…ŒìŠ¤íŠ¸ìš©)
        if max_samples_per_split and len(filtered_data) > max_samples_per_split:
            print(f"Limiting {split_name} split to {max_samples_per_split} samples")
            filtered_data = filtered_data.select(range(max_samples_per_split))
        
        # messages êµ¬ì¡°ë¡œ ë³€í™˜
        if split_name in ['train', 'validation']:
            # í•™ìŠµìš©: system, user, assistant messages
            processed_data = filtered_data.map(
                create_training_messages,
                batched=True,
                fn_kwargs={
                    'training_columns': training_columns,
                    'messages_format': messages_format
                },
                desc=f"Creating training messages for {split_name}"
            )
            
        else:  # test split
            # í‰ê°€ìš©: user messageë§Œ í¬í•¨, referenceëŠ” ë³„ë„ ì €ì¥
            processed_data = filtered_data.map(
                create_evaluation_messages,
                batched=True,
                fn_kwargs={
                    'evaluate_columns': evaluate_columns
                },
                desc=f"Creating evaluation messages for {split_name}"
            )
        
        preprocessed_dataset[split_name] = processed_data
        print(f"{split_name}: {len(dataset[split_name])} -> {len(processed_data)} samples")
    
    return DatasetDict(preprocessed_dataset)

def main():
    args = parse_args()
    
    print("=== Task 1b: Dataset Preprocessing ===")
    
    # ë°ì´í„°ì…‹ ì„¤ì • íŒŒì¼ ë¡œë“œ
    print(f"Loading dataset config from: {args.config}")
    config = load_dataset_config(args.config)
    
    # ì…ë ¥ ê²½ë¡œ ì„¤ì • - íŒŒì´í”„ë¼ì¸ í™˜ê²½ì—ì„œëŠ” ì´ì „ taskì˜ outputì„ input1ì—ì„œ ì½ìŒ
    if settings.is_pipeline_env:
        readonly_input_path = settings.pipeline_input_path
        # ì½ê¸° ì „ìš© ê²½ë¡œë¥¼ ì“°ê¸° ê°€ëŠ¥í•œ ì„ì‹œ ê²½ë¡œë¡œ ë³µì‚¬
        input_path = settings.copy_readonly_to_writable(readonly_input_path, 'preprocess_dataset')
    else:
        input_path = settings.save_dataset_path_raw
    
    # ì›ë³¸ ë°ì´í„°ì…‹ ë¡œë“œ
    if not input_path.exists():
        raise FileNotFoundError(f"Raw dataset not found at: {input_path}")
    
    print(f"Loading raw dataset from: {input_path}")
    raw_dataset = load_from_disk(input_path)
    
    # ë°ì´í„° ì „ì²˜ë¦¬
    preprocessed_dataset = preprocess_dataset(
        raw_dataset, 
        config,
        max_samples_per_split=args.max_samples_per_split
    )
    
    # ì¶œë ¥ ê²½ë¡œ ì„¤ì •
    output_path = settings.save_dataset_path_preprocessed
    
    print(f"Saving preprocessed dataset to: {output_path}")
    if not output_path.exists():
        output_path.mkdir(parents=True, exist_ok=True)

    # ì „ì²˜ë¦¬ëœ ë°ì´í„°ì…‹ ì €ì¥
    preprocessed_dataset.save_to_disk(output_path)
    
    print("\n--- Dataset preprocessing complete ---")
    print("Number of samples in each split after preprocessing:")
    for split_name, split_data in preprocessed_dataset.items():
        print(f"{split_name}: {len(split_data)}")
    
    print("\nSample of preprocessed data:")
    print("Train split sample (messages structure):")
    if 'train' in preprocessed_dataset:
        print(f"Messages: {preprocessed_dataset['train'][0]['messages']}")
        print(f"Reference: {preprocessed_dataset['train'][0]['reference']}")
    
    print("\nTest split sample (evaluation structure):")
    if 'test' in preprocessed_dataset:
        print(f"Messages: {preprocessed_dataset['test'][0]['messages']}")
        print(f"Reference: {preprocessed_dataset['test'][0]['reference']}")
        print(f"Question: {preprocessed_dataset['test'][0]['question']}")
    
    print(f"\nâœ… Preprocessed dataset saved to: {output_path}")
    print(f"ğŸ“„ Configuration used: {args.config}")

if __name__ == "__main__":
    main()
