# VLM Model Configuration
# ë‹¤ì–‘í•œ VLM ëª¨ë¸ì— ëŒ€í•œ í´ë˜ìŠ¤ ë§¤í•‘ ì„¤ì •
#
# ğŸ“ Processor ì„¤ì • ë°©ì‹:
# - processor_classê°€ ì§€ì •ë˜ì§€ ì•Šìœ¼ë©´ ê¸°ë³¸ì ìœ¼ë¡œ AutoProcessor ì‚¬ìš© (ê¶Œì¥)
# - íŠ¹ìˆ˜í•œ processorê°€ í•„ìš”í•œ ëª¨ë¸ë§Œ processor_class ëª…ì‹œì  ì§€ì •
# - ëŒ€ë¶€ë¶„ì˜ VLM ëª¨ë¸ì€ AutoProcessorë¡œ ì¶©ë¶„íˆ í˜¸í™˜ë©ë‹ˆë‹¤

# ëª¨ë¸ë³„ í´ë˜ìŠ¤ ë§¤í•‘
model_classes:
    # SmolVLM ëª¨ë¸ë“¤ (íŠ¹ìˆ˜ processor í•„ìš”)
    "HuggingFaceTB/SmolVLM-Base":
        model_class: "Idefics3ForConditionalGeneration"
        # processor_class: "Idefics3Processor" # íŠ¹ìˆ˜ processor ëª…ì‹œì  ì§€ì •
        import_path: "transformers"

    # Qwen2-VL ëª¨ë¸ë“¤ (íŠ¹ìˆ˜ processor í•„ìš”)
    "Qwen/Qwen2-VL-2B-Instruct":
        model_class: "Qwen2VLForConditionalGeneration"
        # processor_class: "Qwen2VLProcessor" # íŠ¹ìˆ˜ processor ëª…ì‹œì  ì§€ì •
        import_path: "transformers"

    "Qwen/Qwen2-VL-7B-Instruct":
        model_class: "Qwen2VLForConditionalGeneration"
        # processor_class: "Qwen2VLProcessor" # íŠ¹ìˆ˜ processor ëª…ì‹œì  ì§€ì •
        import_path: "transformers"

# ê¸°ë³¸ fallback ì„¤ì • (VLMìš© AutoModel ì‚¬ìš©)
default_fallback:
    model_class: "AutoModelForImageTextToText"
    import_path: "transformers"
    # processor_class ë¯¸ì§€ì • -> AutoProcessor ì‚¬ìš©

# ê³µí†µ ë¡œë”© íŒŒë¼ë¯¸í„°
loading_params:
    torch_dtype: "torch.bfloat16"
    device_map: "auto"
    trust_remote_code: true

# í”„ë¡œì„¸ì„œ ê³µí†µ ì„¤ì •
processor_params:
    trust_remote_code: true
    use_fast: true # fast processor ì§€ì› ëª¨ë¸ìš© (Qwen2-VL, SmolVLM, GLM-4V, LLaVA ë“±)
